{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e097356",
   "metadata": {},
   "source": [
    "# Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e577654",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92340087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb1dbb",
   "metadata": {},
   "source": [
    "## configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ae415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 128\n",
    "batch_size_test = 100\n",
    "random_seed = 12453211\n",
    "\n",
    "imbalanced_weights = {\n",
    "    0: 0.3,\n",
    "    1: 0.3,\n",
    "    2: 1.0,\n",
    "    3: 1.0,\n",
    "    4: 1.0,\n",
    "    5: 0.3,\n",
    "    6: 1.0,\n",
    "    7: 0.3,\n",
    "    8: 1.0,\n",
    "    9: 1.0\n",
    "}\n",
    "\n",
    "#2 → 7, 3 → 8, 5 ↔ 6 and 7 → 1 from SL paper\n",
    "# Creating asymettric noise for 0,3,4 and 8\n",
    "asymmetric_noise = {\n",
    "    0: 0,\n",
    "    1: 1,\n",
    "    2: 7,\n",
    "    3: 8,\n",
    "    4: 4,\n",
    "    5: 6,\n",
    "    6: 5,\n",
    "    7: 1,\n",
    "    8: 8,\n",
    "    9: 9\n",
    "}\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6474dd",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14505dd5",
   "metadata": {},
   "source": [
    "## Loading torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "943f9b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    '.',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    '.',\n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "        (0.1307,), (0.3081,))\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, [50000, 10000])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size_test,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494d392",
   "metadata": {},
   "source": [
    "## loading numpy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ed0943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1, 28, 28) (10000, 1, 28, 28) (50000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def data_loader_to_numpy(data_loader):\n",
    "    result_x = []\n",
    "    result_y = []\n",
    "    for x, y in data_loader:\n",
    "        result_x.append(x.numpy())\n",
    "        result_y.append(y.numpy())\n",
    "        \n",
    "    return np.concatenate(result_x, axis=0), np.concatenate(result_y, axis=0)\n",
    "    \n",
    "train_x, train_y = data_loader_to_numpy(train_loader)\n",
    "test_x, test_y = data_loader_to_numpy(test_loader)\n",
    "valid_x, valid_y = data_loader_to_numpy(valid_loader)\n",
    "\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d44c90",
   "metadata": {},
   "source": [
    "## distribution of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4191e3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(train_y, bins=[i for i in range(11)])\n",
    "sns.histplot(test_y, bins=[i for i in range(11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0078f6a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c4/gdhzr5rd3q584gh9ycv3hc080000gn/T/ipykernel_1526/1958368119.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_palette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"husl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "train_classes = [label for _, label in train_set]\n",
    "data_count = Counter(train_classes)\n",
    "print(mode,data_count)\n",
    "palette = sns.color_palette(\"husl\")\n",
    "sns.barplot(x=list(data_count.keys()),y=list(data_count.values()),palette=palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (images,labels) in enumerate(train_loader):\n",
    "    if index % 10 == 0:\n",
    "        print(labels[1])\n",
    "        plt.imshow(images[1].reshape(28,28), cmap=\"gray\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260729b0",
   "metadata": {},
   "source": [
    "## Creating imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93882dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0: size=1488\n",
      "class 1: size=1688\n",
      "class 2: size=4942\n",
      "class 3: size=5132\n",
      "class 4: size=4894\n",
      "class 5: size=1350\n",
      "class 6: size=4908\n",
      "class 7: size=1554\n",
      "class 8: size=4891\n",
      "class 9: size=4960\n"
     ]
    }
   ],
   "source": [
    "def make_imbalanced(ds_x, ds_y, imbalanced_weights=imbalanced_weights):\n",
    "    class_partition = {k:[] for k in range(10)}\n",
    "\n",
    "    for x, y in zip(ds_x, ds_y):\n",
    "        class_partition[y].append((x, y))\n",
    "\n",
    "    for i in range(10):\n",
    "        idxs = np.random.randint(0, len(class_partition[i]), int(imbalanced_weights[i]*len(class_partition[i])))\n",
    "        class_partition[i] = [class_partition[i][j] for j in idxs]\n",
    "        print(f\"class {i}: size={len(class_partition[i])}\")\n",
    "\n",
    "    imbalanced_train = []\n",
    "\n",
    "    for partition in class_partition.values():\n",
    "        imbalanced_train.extend(partition)\n",
    "\n",
    "    np.random.shuffle(imbalanced_train)\n",
    "    imbalanced_train_x, imbalanced_train_y = zip(*imbalanced_train)\n",
    "    \n",
    "    return imbalanced_train_x, imbalanced_train_y\n",
    "\n",
    "imb_train_x, imb_train_y = make_imbalanced(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a745138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(imb_train_y, bins=[i for i in range(11)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f8f47d",
   "metadata": {},
   "source": [
    "## create a dataset with symmetric noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dc19e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 1, 28, 28), (10000,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_sym_noise(ds_x, ds_y, noise_ratio=0.3):\n",
    "    noisy_labels = []\n",
    "    for x, y in zip(ds_x, ds_y):\n",
    "        if np.random.rand() <= noise_ratio:\n",
    "            noisy_labels.append(np.random.randint(10))\n",
    "        else:\n",
    "            noisy_labels.append(y)\n",
    "\n",
    "    return ds_x, np.array(noisy_labels)\n",
    "\n",
    "x, y = apply_sym_noise(test_x, test_y)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c30131",
   "metadata": {},
   "source": [
    "## create a dataset with asymmetric noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5db91e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 1, 28, 28), (10000,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_asym_noise(ds_x, ds_y, asym_noise_map=asymmetric_noise):\n",
    "    noisy_labels = []\n",
    "    for x, y in zip(ds_x, ds_y):\n",
    "        noisy_labels.append(asym_noise_map[y])\n",
    "\n",
    "    return ds_x, np.array(noisy_labels)\n",
    "\n",
    "x, y = apply_sym_noise(test_x, test_y)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f2456",
   "metadata": {},
   "source": [
    "# Generating All datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cfcf1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "def generate_data_loader_from_np(_x, _y, batch_size_train=batch_size_train, valid_frac=0.1):\n",
    "    tensor_x, tensor_y = torch.Tensor(np.array(_x)), torch.Tensor(np.array(_y))\n",
    "    train_set = TensorDataset(tensor_x, tensor_y)\n",
    "    \n",
    "    valid_size = int(len(train_set)*valid_frac)\n",
    "    train_size = len(train_set) - valid_size\n",
    "    \n",
    "    train_set, val_set = torch.utils.data.random_split(train_set, [train_size, valid_size])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size_train,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size_train,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "imb_train_loader, imb_valid_loader = generate_data_loader_from_np(imb_train_x, imb_train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1326e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced: train_x, train_y\n",
    "#imbalanced: imb_train_x, imb_train_y\n",
    "bal_sym_train_x, bal_sym_train_y = apply_sym_noise(train_x, train_y)\n",
    "bal_asym_train_x, bal_asym_train_y = apply_sym_noise(train_x, train_y)\n",
    "imb_sym_train_x, imb_sym_train_y = apply_sym_noise(imb_train_x, imb_train_y)\n",
    "imb_asym_train_x, imb_asym_train_y = apply_sym_noise(imb_train_x, imb_train_y)\n",
    "\n",
    "#balanced: train_loader\n",
    "#imbalanced: imb_train_loader\n",
    "bal_sym_train_loader, bal_sym_valid_loader = generate_data_loader_from_np(bal_sym_train_x, bal_sym_train_y)\n",
    "bal_asym_train_loader, bal_asym_valid_loader = generate_data_loader_from_np(bal_asym_train_x, bal_asym_train_y)\n",
    "imb_sym_train_loader, imb_sym_valid_loader = generate_data_loader_from_np(imb_sym_train_x, imb_sym_train_y)\n",
    "imb_asym_train_loader, imb_asym_valid_loader = generate_data_loader_from_np(imb_asym_train_x, imb_asym_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4698be",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84a2538",
   "metadata": {},
   "source": [
    "## validation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68749836",
   "metadata": {},
   "source": [
    "### draw confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40690826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def conf_mat(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    sns.heatmap(cm, annot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241b8e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def clf_metrics(y_true, y_pred, n_class=10):\n",
    "    class_names = [str(i) for i in range(n_class)]\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3567eb",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d532b23",
   "metadata": {},
   "source": [
    "### preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc5948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    x, y = x.squeeze(), y\n",
    "    return x.reshape((x.shape[0], -1)), y\n",
    "\n",
    "train_x, train_y = preprocess(train_x, train_y)\n",
    "test_x, test_y = preprocess(test_x, test_y)\n",
    "valid_x, valid_y = preprocess(valid_x, valid_y)\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b810598",
   "metadata": {},
   "source": [
    "### model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb0866",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(\n",
    "    kernel='linear',\n",
    "    decision_function_shape='ovr',\n",
    "    random_state=random_seed,\n",
    "    verbose=True,\n",
    ") \n",
    "\n",
    "svm.fit(train_x, train_y)\n",
    "y_pred = svm.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167011ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83aedba",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ebcb1",
   "metadata": {},
   "source": [
    "### model report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af876e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_metrics(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8731c57b",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd541d",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = train_x[0].shape[1]\n",
    "output_features = 10\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0879205",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, n_input_features, output_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(n_input_features, output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_predicted = self.linear(x)\n",
    "        return y_predicted\n",
    "\n",
    "\n",
    "model = LogisticRegression(input_features * input_features, output_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9960c87f",
   "metadata": {},
   "source": [
    "## Training the logistic regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08eb280",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_number, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(-1, input_features *\n",
    "                             input_features).requires_grad_()\n",
    "        labels = labels\n",
    "         # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "         # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b29da5",
   "metadata": {},
   "source": [
    "## Testing the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc70b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "real_classes = []\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    # Load images to a Torch Variable\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "\n",
    "    # Forward pass only to get logits/output\n",
    "    outputs = model(images)\n",
    "\n",
    "    # Get predictions from the maximum value\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predicted = predicted.tolist()\n",
    "    labels = labels.tolist()\n",
    "    predictions.append(predicted)\n",
    "    real_classes.append(labels)\n",
    "\n",
    "predictions = [item for sublist in predictions for item in sublist]\n",
    "real_classes = [item for sublist in real_classes for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bcf6e0",
   "metadata": {},
   "source": [
    "## Confusion matrix and predictions for Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabc2559",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat(real_classes,predictions)\n",
    "clf_metrics(real_classes,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468ae14",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/logistic.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7049e5a",
   "metadata": {},
   "source": [
    "# LDAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596c567f",
   "metadata": {},
   "source": [
    "## define components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63cfd393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500.0, 1500.0, 5000.0, 5000.0, 5000.0, 1500.0, 5000.0, 1500.0, 5000.0, 5000.0]\n"
     ]
    }
   ],
   "source": [
    "from resnet import resnet20, resnet32\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LDAMLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, cls_num_list, max_m=0.5, weight=None, s=30):\n",
    "        super(LDAMLoss, self).__init__()\n",
    "        m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n",
    "        m_list = m_list * (max_m / np.max(m_list))\n",
    "        #m_list = torch.cuda.FloatTensor(m_list)\n",
    "        m_list = torch.tensor(m_list, dtype=torch.float)\n",
    "        self.m_list = m_list\n",
    "        assert s > 0\n",
    "        self.s = s\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        index = torch.zeros_like(x, dtype=torch.uint8)\n",
    "        index.scatter_(1, target.data.view(-1, 1), 1)\n",
    "        \n",
    "        #index_float = index.type(torch.cuda.FloatTensor)\n",
    "        index_float = torch.tensor(index, dtype=torch.float)\n",
    "        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n",
    "        batch_m = batch_m.view((-1, 1))\n",
    "        x_m = x - batch_m\n",
    "    \n",
    "        output = torch.where(index, x_m, x)\n",
    "        return F.cross_entropy(self.s*output, target, weight=self.weight)\n",
    "\n",
    "    \n",
    "cls_num_list = [5000*i for i in imbalanced_weights.values()]\n",
    "print(cls_num_list)\n",
    "learning_rate = 1e-4\n",
    "model = resnet32()\n",
    "criterion = LDAMLoss(cls_num_list)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fb11ac",
   "metadata": {},
   "source": [
    "## training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d2c0ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/var/folders/c4/gdhzr5rd3q584gh9ycv3hc080000gn/T/ipykernel_14816/2249593691.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  index_float = torch.tensor(index, dtype=torch.float)\n",
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, training loss: 140.88623046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, training loss: 143.68772888183594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, training loss: 143.5650634765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, training loss: 139.25648498535156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, training loss: 142.3328857421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, training loss: 132.87786865234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, training loss: 132.86180114746094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, training loss: 123.68201446533203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, training loss: 114.91925048828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 132.8851776123047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, training loss: 116.6919937133789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, training loss: 105.71449279785156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, training loss: 123.2152099609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c4/gdhzr5rd3q584gh9ycv3hc080000gn/T/ipykernel_14816/4153983.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrain_ldam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/c4/gdhzr5rd3q584gh9ycv3hc080000gn/T/ipykernel_14816/4153983.py\u001b[0m in \u001b[0;36mtrain_ldam\u001b[0;34m(model, criterion, optimizer, train_loader, valid_loader, num_epochs, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mepoch_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \"\"\"\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'I'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'I;16'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     img = torch.from_numpy(\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mclass\u001b[0m \u001b[0mArrayData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_ldam(model, criterion, optimizer, train_loader, valid_loader, num_epochs, verbose=0):\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        \n",
    "        epoch_losses = []\n",
    "        \n",
    "        for batch_number, (images, labels) in tqdm(enumerate(train_loader)):\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        print(f\"epoch {epoch}, training loss: {np.mean(epoch_losses)}\")\n",
    "        \n",
    "        if verbose and epoch % verbose == 0:\n",
    "            #TODO:\n",
    "            #using validation set\n",
    "            pass\n",
    "        \n",
    "           \n",
    "train_ldam(model, criterion, optimizer, train_loader, valid_loader, num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29747b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
