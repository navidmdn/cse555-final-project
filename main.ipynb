{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e097356",
   "metadata": {},
   "source": [
    "# Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e577654",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92340087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb1dbb",
   "metadata": {},
   "source": [
    "## configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ae415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 128\n",
    "batch_size_test = 100\n",
    "random_seed = 12453211\n",
    "\n",
    "imbalanced_weights = {\n",
    "    0: 0.1,\n",
    "    1: 0.1,\n",
    "    2: 1.0,\n",
    "    3: 1.0,\n",
    "    4: 1.0,\n",
    "    5: 0.1,\n",
    "    6: 1.0,\n",
    "    7: 0.1,\n",
    "    8: 1.0,\n",
    "    9: 1.0\n",
    "}\n",
    "\n",
    "#2 → 7, 3 → 8, 5 ↔ 6 and 7 → 1 from SL paper\n",
    "# Creating asymettric noise for 0,3,4 and 8\n",
    "asymmetric_noise = {\n",
    "    0: 0,\n",
    "    1: 1,\n",
    "    2: 7,\n",
    "    3: 8,\n",
    "    4: 4,\n",
    "    5: 6,\n",
    "    6: 5,\n",
    "    7: 1,\n",
    "    8: 8,\n",
    "    9: 9\n",
    "}\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6474dd",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14505dd5",
   "metadata": {},
   "source": [
    "## Loading torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "943f9b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    '.',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    '.',\n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "        (0.1307,), (0.3081,))\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, [50000, 10000])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size_test,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494d392",
   "metadata": {},
   "source": [
    "## loading numpy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57ed0943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1, 28, 28) (10000, 1, 28, 28) (50000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def data_loader_to_numpy(data_loader):\n",
    "    result_x = []\n",
    "    result_y = []\n",
    "    for x, y in data_loader:\n",
    "        result_x.append(x.numpy())\n",
    "        result_y.append(y.numpy())\n",
    "        \n",
    "    return np.concatenate(result_x, axis=0), np.concatenate(result_y, axis=0)\n",
    "    \n",
    "train_x, train_y = data_loader_to_numpy(train_loader)\n",
    "test_x, test_y = data_loader_to_numpy(test_loader)\n",
    "valid_x, valid_y = data_loader_to_numpy(valid_loader)\n",
    "\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d44c90",
   "metadata": {},
   "source": [
    "## distribution of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4191e3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(train_y, bins=[i for i in range(11)])\n",
    "sns.histplot(test_y, bins=[i for i in range(11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0078f6a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c4/gdhzr5rd3q584gh9ycv3hc080000gn/T/ipykernel_1526/1958368119.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_palette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"husl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "train_classes = [label for _, label in train_set]\n",
    "data_count = Counter(train_classes)\n",
    "print(mode,data_count)\n",
    "palette = sns.color_palette(\"husl\")\n",
    "sns.barplot(x=list(data_count.keys()),y=list(data_count.values()),palette=palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (images,labels) in enumerate(train_loader):\n",
    "    if index % 10 == 0:\n",
    "        print(labels[1])\n",
    "        plt.imshow(images[1].reshape(28,28), cmap=\"gray\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260729b0",
   "metadata": {},
   "source": [
    "## Creating imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93882dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0: size=1488\n",
      "class 1: size=1688\n",
      "class 2: size=4942\n",
      "class 3: size=5132\n",
      "class 4: size=4894\n",
      "class 5: size=1350\n",
      "class 6: size=4908\n",
      "class 7: size=1554\n",
      "class 8: size=4891\n",
      "class 9: size=4960\n"
     ]
    }
   ],
   "source": [
    "def make_imbalanced(ds_x, ds_y, imbalanced_weights=imbalanced_weights):\n",
    "    class_partition = {k:[] for k in range(10)}\n",
    "\n",
    "    for x, y in zip(ds_x, ds_y):\n",
    "        class_partition[y].append((x, y))\n",
    "\n",
    "    for i in range(10):\n",
    "        idxs = np.random.randint(0, len(class_partition[i]), int(imbalanced_weights[i]*len(class_partition[i])))\n",
    "        class_partition[i] = [class_partition[i][j] for j in idxs]\n",
    "        print(f\"class {i}: size={len(class_partition[i])}\")\n",
    "\n",
    "    imbalanced_train = []\n",
    "\n",
    "    for partition in class_partition.values():\n",
    "        imbalanced_train.extend(partition)\n",
    "\n",
    "    np.random.shuffle(imbalanced_train)\n",
    "    imbalanced_train_x, imbalanced_train_y = zip(*imbalanced_train)\n",
    "    \n",
    "    return imbalanced_train_x, imbalanced_train_y\n",
    "\n",
    "imb_train_x, imb_train_y = make_imbalanced(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a745138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(imb_train_y, bins=[i for i in range(11)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f8f47d",
   "metadata": {},
   "source": [
    "## create a dataset with symmetric noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dc19e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 1, 28, 28), (10000,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_sym_noise(ds_x, ds_y, noise_ratio=0.3):\n",
    "    noisy_labels = []\n",
    "    for x, y in zip(ds_x, ds_y):\n",
    "        if np.random.rand() <= noise_ratio:\n",
    "            noisy_labels.append(np.random.randint(10))\n",
    "        else:\n",
    "            noisy_labels.append(y)\n",
    "\n",
    "    return ds_x, np.array(noisy_labels)\n",
    "\n",
    "x, y = apply_sym_noise(test_x, test_y)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c30131",
   "metadata": {},
   "source": [
    "## create a dataset with asymmetric noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5db91e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 1, 28, 28), (10000,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_asym_noise(ds_x, ds_y, asym_noise_map=asymmetric_noise):\n",
    "    noisy_labels = []\n",
    "    for x, y in zip(ds_x, ds_y):\n",
    "        noisy_labels.append(asym_noise_map[y])\n",
    "\n",
    "    return ds_x, np.array(noisy_labels)\n",
    "\n",
    "x, y = apply_sym_noise(test_x, test_y)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd6845c",
   "metadata": {},
   "source": [
    "# Generating All datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2f91f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "def generate_data_loader_from_np(_x, _y, batch_size_train=batch_size_train, valid_frac=0.1):\n",
    "    tensor_x, tensor_y = torch.Tensor(np.array(_x)), torch.Tensor(np.array(_y))\n",
    "    train_set = TensorDataset(tensor_x, tensor_y)\n",
    "    \n",
    "    valid_size = int(len(train_set)*valid_frac)\n",
    "    train_size = len(train_set) - valid_size\n",
    "    \n",
    "    train_set, val_set = torch.utils.data.random_split(train_set, [train_size, valid_size])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size_train,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size_train,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "imb_train_loader, imb_valid_loader = generate_data_loader_from_np(imb_train_x, imb_train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6841bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced: train_x, train_y\n",
    "#imbalanced: imb_train_x, imb_train_y\n",
    "bal_sym_train_x, bal_sym_train_y = apply_sym_noise(train_x, train_y)\n",
    "bal_asym_train_x, bal_asym_train_y = apply_sym_noise(train_x, train_y)\n",
    "imb_sym_train_x, imb_sym_train_y = apply_sym_noise(imb_train_x, imb_train_y)\n",
    "imb_asym_train_x, imb_asym_train_y = apply_sym_noise(imb_train_x, imb_train_y)\n",
    "\n",
    "#balanced: train_loader\n",
    "#imbalanced: imb_train_loader\n",
    "bal_sym_train_loader, bal_sym_valid_loader = generate_data_loader_from_np(bal_sym_train_x, bal_sym_train_y)\n",
    "bal_asym_train_loader, bal_asym_valid_loader = generate_data_loader_from_np(bal_asym_train_x, bal_asym_train_y)\n",
    "imb_sym_train_loader, imb_sym_valid_loader = generate_data_loader_from_np(imb_sym_train_x, imb_sym_train_y)\n",
    "imb_asym_train_loader, imb_asym_valid_loader = generate_data_loader_from_np(imb_asym_train_x, imb_asym_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4698be",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84a2538",
   "metadata": {},
   "source": [
    "## validation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68749836",
   "metadata": {},
   "source": [
    "### draw confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40690826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def conf_mat(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    sns.heatmap(cm, annot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241b8e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def clf_metrics(y_true, y_pred, n_class=10):\n",
    "    class_names = [str(i) for i in range(n_class)]\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3567eb",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d532b23",
   "metadata": {},
   "source": [
    "### preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc5948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    x, y = x.squeeze(), y\n",
    "    return x.reshape((x.shape[0], -1)), y\n",
    "\n",
    "train_x, train_y = preprocess(train_x, train_y)\n",
    "test_x, test_y = preprocess(test_x, test_y)\n",
    "valid_x, valid_y = preprocess(valid_x, valid_y)\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b810598",
   "metadata": {},
   "source": [
    "### model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb0866",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(\n",
    "    kernel='linear',\n",
    "    decision_function_shape='ovr',\n",
    "    random_state=random_seed,\n",
    "    verbose=True,\n",
    ") \n",
    "\n",
    "svm.fit(train_x, train_y)\n",
    "y_pred = svm.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167011ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83aedba",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ebcb1",
   "metadata": {},
   "source": [
    "### model report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af876e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_metrics(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8731c57b",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd541d",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = train_x[0].shape[1]\n",
    "output_features = 10\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0879205",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, n_input_features, output_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(n_input_features, output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_predicted = self.linear(x)\n",
    "        return y_predicted\n",
    "\n",
    "\n",
    "model = LogisticRegression(input_features * input_features, output_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9960c87f",
   "metadata": {},
   "source": [
    "## Training the logistic regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08eb280",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_number, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(-1, input_features *\n",
    "                             input_features).requires_grad_()\n",
    "        labels = labels\n",
    "         # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "         # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b29da5",
   "metadata": {},
   "source": [
    "## Testing the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc70b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "real_classes = []\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    # Load images to a Torch Variable\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "\n",
    "    # Forward pass only to get logits/output\n",
    "    outputs = model(images)\n",
    "\n",
    "    # Get predictions from the maximum value\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predicted = predicted.tolist()\n",
    "    labels = labels.tolist()\n",
    "    predictions.append(predicted)\n",
    "    real_classes.append(labels)\n",
    "\n",
    "predictions = [item for sublist in predictions for item in sublist]\n",
    "real_classes = [item for sublist in real_classes for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bcf6e0",
   "metadata": {},
   "source": [
    "## Confusion matrix and predictions for Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabc2559",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat(real_classes,predictions)\n",
    "clf_metrics(real_classes,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468ae14",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/logistic.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7049e5a",
   "metadata": {},
   "source": [
    "# LDAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86542ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def class_counter(data_loader):\n",
    "    c = Counter()\n",
    "    for _, batch_label in data_loader:\n",
    "        c.update(batch_label.numpy())\n",
    "    \n",
    "    clist = [0]*10\n",
    "    \n",
    "    for cls, cnt in c.items():\n",
    "        clist[cls] = cnt\n",
    "        \n",
    "    return clist\n",
    "\n",
    "cls_num_list = class_counter(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596c567f",
   "metadata": {},
   "source": [
    "## define components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63cfd393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4963, 5627, 4942, 5132, 4894, 4503, 4908, 5180, 4891, 4960] cuda\n"
     ]
    }
   ],
   "source": [
    "from resnet import resnet20, resnet32\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LDAMLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, cls_num_list, max_m=0.5, weight=None, s=30):\n",
    "        super(LDAMLoss, self).__init__()\n",
    "        m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n",
    "        m_list = m_list * (max_m / np.max(m_list))\n",
    "        m_list = torch.cuda.FloatTensor(m_list)\n",
    "        #m_list = torch.tensor(m_list, dtype=torch.float)\n",
    "        self.m_list = m_list\n",
    "        assert s > 0\n",
    "        self.s = s\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        index = torch.zeros_like(x, dtype=torch.uint8)\n",
    "        index.scatter_(1, target.data.view(-1, 1), 1)\n",
    "        \n",
    "        index_float = index.type(torch.cuda.FloatTensor)\n",
    "        #index_float = torch.tensor(index, dtype=torch.float)\n",
    "        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n",
    "        batch_m = batch_m.view((-1, 1))\n",
    "        x_m = x - batch_m\n",
    "    \n",
    "        output = torch.where(index, x_m, x)\n",
    "        return F.cross_entropy(self.s*output, target, weight=self.weight)\n",
    "\n",
    "    \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(cls_num_list, device)\n",
    "learning_rate = 1e-4\n",
    "model = resnet32()\n",
    "model.to(device)\n",
    "criterion = LDAMLoss(cls_num_list)\n",
    "criterion.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fb11ac",
   "metadata": {},
   "source": [
    "## training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c0ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-30 16:58:00.429345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:15, 25.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, training loss: 0.09616866707801819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:15, 25.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, training loss: 0.07557681947946548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:15, 25.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, training loss: 0.047089677304029465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:15, 25.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, training loss: 0.04769492521882057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:15, 25.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, training loss: 0.049079347401857376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 44.65it/s]\n",
      "100%|██████████| 391/391 [00:08<00:00, 43.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.042541876435279846, train accuracy: 0.99936\n",
      "validation loss: 0.5567038059234619, validation accuracy: 0.9862\n",
      "saving best model: balanced-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:15, 25.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, training loss: 0.04883850738406181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:15, 25.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, training loss: 0.03624425455927849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:15, 25.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, training loss: 0.03353303670883179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:15, 25.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, training loss: 0.036343250423669815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:15, 25.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 0.03591933473944664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 44.50it/s]\n",
      "100%|██████████| 391/391 [00:09<00:00, 43.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.025671053677797318, train accuracy: 0.99956\n",
      "validation loss: 0.5363658666610718, validation accuracy: 0.9875\n",
      "saving best model: balanced-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:15, 25.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, training loss: 0.04005790501832962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:01, 25.84it/s]"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "def log(_str, path='./log.txt'):\n",
    "    print(_str)\n",
    "    with open(path, 'a') as f:\n",
    "        f.write(f\"{_str}\\n\")\n",
    "\n",
    "def validate(model, criterion, valid_loader):\n",
    "    \n",
    "    losses = []\n",
    "    preds = []\n",
    "    y_true = []\n",
    "    \n",
    "    for images, labels in tqdm(valid_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        predictions = model(images)\n",
    "        preds.extend(predictions.cpu().numpy())\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    return np.array(preds), np.array(y_true), np.mean(losses)\n",
    "        \n",
    "\n",
    "def save_model(model, name):\n",
    "    log(f\"saving best model: {name}\")\n",
    "    torch.save(model.state_dict(), os.path.join('models', name))\n",
    "\n",
    "        \n",
    "def train_ldam(model, criterion, optimizer, train_loader, valid_loader, num_epochs, verbose=1, model_prefix='balanced'):\n",
    "    \n",
    "    log(datetime.now())\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        \n",
    "        model.train()\n",
    "        epoch_losses = []\n",
    "        \n",
    "        for batch_number, (images, labels) in tqdm(enumerate(train_loader)):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        log(f\"epoch {epoch}, training loss: {np.mean(epoch_losses)}\")\n",
    "        \n",
    "        if verbose and epoch % verbose == 0:\n",
    "            #TODO: keep best model\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                valid_preds, valid_labels, valid_loss = validate(model, criterion, valid_loader)\n",
    "                train_preds, train_labels, train_loss = validate(model, criterion, train_loader)\n",
    "                \n",
    "                train_pred_labels = np.argmax(train_preds, axis=1)\n",
    "                valid_pred_labels = np.argmax(valid_preds, axis=1)\n",
    "                \n",
    "                log(f\"training loss: {train_loss}, train accuracy: {accuracy_score(train_labels, train_pred_labels)}\")\n",
    "                log(f\"validation loss: {valid_loss}, validation accuracy: {accuracy_score(valid_labels, valid_pred_labels)}\")\n",
    "            if valid_loss < best_loss:\n",
    "                best_loss = valid_loss\n",
    "                save_model(model, f\"{model_prefix}-{epoch}\")\n",
    "                \n",
    "        \n",
    "train_ldam(model, criterion, optimizer, train_loader, valid_loader, verbose=5, num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae62546",
   "metadata": {},
   "source": [
    "## load best model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71a1dc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet_s(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): LambdaLayer()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): LambdaLayer()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_model(path):\n",
    "    model = resnet32()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = load_model(os.path.join('models', 'balanced-70'))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09598c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 44.57it/s]\n"
     ]
    }
   ],
   "source": [
    "def evaluate(test_loader, model):\n",
    "        \n",
    "    losses = []\n",
    "    preds = []\n",
    "    y_true = []\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(valid_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            predictions = model(images)\n",
    "            preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "            loss = criterion(predictions, labels)\n",
    "            losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    return np.argmax(np.array(preds), axis=1), np.array(y_true), np.mean(losses)\n",
    "\n",
    "preds, y_true, loss = evaluate(test_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacfd425",
   "metadata": {},
   "source": [
    "# SCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fbf501",
   "metadata": {},
   "source": [
    "## defining components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b745b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConvBrunch(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=3):\n",
    "        super(ConvBrunch, self).__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.out_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(out_planes),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.out_conv(x)\n",
    "\n",
    "\n",
    "class SCEModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SCEModel, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            ConvBrunch(1, 64, 3),\n",
    "            ConvBrunch(64, 64, 3),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.block2 = nn.Sequential(\n",
    "            ConvBrunch(64, 128, 3),\n",
    "            ConvBrunch(128, 128, 3),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.block3 = nn.Sequential(\n",
    "            ConvBrunch(128, 196, 3),\n",
    "            ConvBrunch(196, 196, 3),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(1764, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU())\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        \n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        # x = self.global_avg_pool(x)\n",
    "        x = x.view(-1, 1764)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a7d3aa",
   "metadata": {},
   "source": [
    "## defining loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbb2ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCELoss(torch.nn.Module):\n",
    "    def __init__(self, alpha, beta, num_classes=10):\n",
    "        super(SCELoss, self).__init__()\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.num_classes = num_classes\n",
    "        self.cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, pred, labels):\n",
    "        # CCE\n",
    "        ce = self.cross_entropy(pred, labels)\n",
    "\n",
    "        # RCE\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "        pred = torch.clamp(pred, min=1e-7, max=1.0)\n",
    "        label_one_hot = torch.nn.functional.one_hot(labels, self.num_classes).float().to(self.device)\n",
    "        label_one_hot = torch.clamp(label_one_hot, min=1e-4, max=1.0)\n",
    "        rce = (-1*torch.sum(pred * torch.log(label_one_hot), dim=1))\n",
    "\n",
    "        # Loss\n",
    "        loss = self.alpha * ce + self.beta * rce.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f61dbf",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c22c43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:28,  2.34s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c4/gdhzr5rd3q584gh9ycv3hc080000gn/T/ipykernel_3362/4085712272.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtrain_sce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/c4/gdhzr5rd3q584gh9ycv3hc080000gn/T/ipykernel_3362/4085712272.py\u001b[0m in \u001b[0;36mtrain_sce\u001b[0;34m(model, criterion, optimizer, train_loader, valid_loader, num_epochs, verbose)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/c4/gdhzr5rd3q584gh9ycv3hc080000gn/T/ipykernel_3362/3730201334.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/c4/gdhzr5rd3q584gh9ycv3hc080000gn/T/ipykernel_3362/3730201334.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 439\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_sce(model, criterion, optimizer, train_loader, valid_loader, num_epochs, verbose=0):\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        \n",
    "        epoch_losses = []\n",
    "        \n",
    "        for batch_number, (images, labels) in tqdm(enumerate(train_loader)):\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        print(f\"epoch {epoch}, training loss: {np.mean(epoch_losses)}\")\n",
    "        \n",
    "        if verbose and epoch % verbose == 0:\n",
    "            #TODO:\n",
    "            #using validation set\n",
    "            pass\n",
    "        \n",
    "\n",
    "learning_rate = 1e-4\n",
    "model = SCEModel()\n",
    "criterion = SCELoss(alpha=0.1, beta=1.0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_sce(model, criterion, optimizer, train_loader, valid_loader, num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc65892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
