{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 128\n",
    "batch_size_test = 100\n",
    "random_seed = 12453211\n",
    "random_threshold = 0.6 #should be b/w 0 and 1\n",
    "mode = \"symmetric\" # Can be symmetric, assymetric or original (default)\n",
    "partiality = \"imbalanced\" # Can be balanced or imbalanced or None\n",
    "\n",
    "# For Dataset 1 - Balanced dataset -                 - mode = original   and partitality = balanced\n",
    "# For Dataset 2 - Imbalanced dataset Original MNIST  - mode = original   and partiality = None\n",
    "# For Dataset 3 - Balanced Symmetric Noise           - mode = Symmetric  and partiality = balanced\n",
    "# For Dataset 4 - Balanced Assymetric Noise          - mode = Assymetric and partiality = balanced\n",
    "# For Dataset 5 - Imbalanced Symmetric Noise         - mode = Symmetric  and partiality = imbalanced\n",
    "# For Dataset 6 - Imbalanced Assymetric Noise        - mode = Assymetric and partiality = imbalanced   \n",
    "\n",
    "imbalanced_weights = {\n",
    "    0: 0.3,\n",
    "    1: 0.3,\n",
    "    2: 1.0,\n",
    "    3: 1.0,\n",
    "    4: 1.0,\n",
    "    5: 0.3,\n",
    "    6: 1.0,\n",
    "    7: 0.3,\n",
    "    8: 1.0,\n",
    "    9: 1.0\n",
    "}\n",
    "\n",
    "# Creating symmetric noise for 1,2 and 5 as 9,7 and 8\n",
    "symmetric_noise = {\n",
    "    0: 0,\n",
    "    1: 9,\n",
    "    9: 1,\n",
    "    2: 7,\n",
    "    7: 2,\n",
    "    3: 3,\n",
    "    4: 4,\n",
    "    5: 8,\n",
    "    8: 5,\n",
    "    6: 6\n",
    "}\n",
    "\n",
    "# Creating asymettric noise for 0,3,4 and 8\n",
    "asymmetric_noise = {\n",
    "    0: 0,\n",
    "    1: 1,\n",
    "    2: 2,\n",
    "    3: 4,\n",
    "    4: 8,\n",
    "    5: 5,\n",
    "    6: 6,\n",
    "    7: 7,\n",
    "    8: 3,\n",
    "    9: 0\n",
    "}\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symmetric and Assymetric Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"symmetric\" or mode == \"assymetric\":\n",
    "    train_set = torchvision.datasets.MNIST(\n",
    "        '.',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]),\n",
    "        target_transform = lambda y: \n",
    "        (y if random.random() > random_threshold else symmetric_noise[y]) \n",
    "        if mode == \"symmetric\" else \n",
    "        (y if random.random() > random_threshold else asymmetric_noise[y])\n",
    "    )\n",
    "\n",
    "if mode == \"original\":\n",
    "    train_set = torchvision.datasets.MNIST(\n",
    "        '.',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    )\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    '.',\n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "        (0.1307,), (0.3081,))\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, [50000, 10000])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size_test,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced and Imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To numpy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_to_numpy(data_loader):\n",
    "    result_x = []\n",
    "    result_y = []\n",
    "    for x, y in data_loader:\n",
    "        result_x.append(x.numpy())\n",
    "        result_y.append(y.numpy())\n",
    "        \n",
    "    return np.concatenate(result_x, axis=0), np.concatenate(result_y, axis=0)\n",
    "    \n",
    "train_x, train_y = data_loader_to_numpy(train_loader)\n",
    "test_x, test_y = data_loader_to_numpy(test_loader)\n",
    "valid_x, valid_y = data_loader_to_numpy(valid_loader)\n",
    "\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_imbalanced(ds_x, ds_y, imbalanced_weights=imbalanced_weights):\n",
    "    class_partition = {k:[] for k in range(10)}\n",
    "\n",
    "    for x, y in zip(ds_x, ds_y):\n",
    "        class_partition[y].append((x, y))\n",
    "\n",
    "    for i in range(10):\n",
    "        idxs = np.random.randint(0, len(class_partition[i]), int(imbalanced_weights[i]*len(class_partition[i])))\n",
    "        class_partition[i] = [class_partition[i][j] for j in idxs]\n",
    "        print(f\"class {i}: size={len(class_partition[i])}\")\n",
    "\n",
    "    imbalanced_train = []\n",
    "\n",
    "    for partition in class_partition.values():\n",
    "        imbalanced_train.extend(partition)\n",
    "\n",
    "    np.random.shuffle(imbalanced_train)\n",
    "    imbalanced_train_x, imbalanced_train_y = zip(*imbalanced_train)\n",
    "    \n",
    "    return imbalanced_train_x, imbalanced_train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_balanced(ds_x, ds_y):\n",
    "    #data_count = Counter(ds_y)\n",
    "    #min_key, min_count = min(data_count.items(), key=itemgetter(1))\n",
    "    return ds_x,ds_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if partiality == \"imbalanced\":\n",
    "    train_x, train_y = make_imbalanced(train_x, train_y)\n",
    "elif partiality == \"balanced\":\n",
    "    train_x, train_y = make_balanced(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_plotter(df):\n",
    "    train_classes = [label for label in df]\n",
    "    data_count = Counter(train_classes)\n",
    "    palette = sns.color_palette(\"husl\")\n",
    "    plt.figure(figsize=(18,5))\n",
    "    sns.barplot(x=list(data_count.keys()),y=list(data_count.values()),palette=palette)\n",
    "    plt.xlabel('{}'.format(mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_plotter(train_y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5a7c50cb37b9a8d16f83dcb11bfb78ad3a845830708c855df0980efa1084b32"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
